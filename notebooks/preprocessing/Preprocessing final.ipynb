{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad1fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835543db",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 180. MiB for an array with shape (5, 4729512) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leo57\\OneDrive\\Documents\\Projet Datascientest\\Fev23_BDS_NBA\\notebooks\\preprocessing\\Preprocessing final.ipynb Cell 2\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leo57/OneDrive/Documents/Projet%20Datascientest/Fev23_BDS_NBA/notebooks/preprocessing/Preprocessing%20final.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Importation des 2 DataFrame\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/leo57/OneDrive/Documents/Projet%20Datascientest/Fev23_BDS_NBA/notebooks/preprocessing/Preprocessing%20final.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m./../../data/NBA Shot Locations 1997 - 2020.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leo57/OneDrive/Documents/Projet%20Datascientest/Fev23_BDS_NBA/notebooks/preprocessing/Preprocessing%20final.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m rank \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m./../../data/ranking.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1789\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1786\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1787\u001b[0m         new_rows \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(index)\n\u001b[1;32m-> 1789\u001b[0m     df \u001b[39m=\u001b[39m DataFrame(col_dict, columns\u001b[39m=\u001b[39;49mcolumns, index\u001b[39m=\u001b[39;49mindex)\n\u001b[0;32m   1791\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m new_rows\n\u001b[0;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msqueeze \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39mcolumns) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    657\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    658\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    659\u001b[0m     )\n\u001b[0;32m    661\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    662\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 663\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    664\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    665\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:494\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    491\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    492\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 494\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:155\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    152\u001b[0m axes \u001b[39m=\u001b[39m [columns, index]\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[39mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    156\u001b[0m         arrays, axes, consolidate\u001b[39m=\u001b[39;49mconsolidate\n\u001b[0;32m    157\u001b[0m     )\n\u001b[0;32m    158\u001b[0m \u001b[39melif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2166\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate)\u001b[0m\n\u001b[0;32m   2149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2150\u001b[0m     arrays: \u001b[39mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2151\u001b[0m     axes: \u001b[39mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2162\u001b[0m     \u001b[39m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2163\u001b[0m     \u001b[39m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2165\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2166\u001b[0m         blocks \u001b[39m=\u001b[39m _form_blocks(arrays, consolidate)\n\u001b[0;32m   2167\u001b[0m         mgr \u001b[39m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2168\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2240\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate)\u001b[0m\n\u001b[0;32m   2237\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(dtype\u001b[39m.\u001b[39mtype, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m)):\n\u001b[0;32m   2238\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39mobject\u001b[39m)\n\u001b[1;32m-> 2240\u001b[0m values, placement \u001b[39m=\u001b[39m _stack_arrays(\u001b[39mlist\u001b[39;49m(tup_block), dtype)\n\u001b[0;32m   2241\u001b[0m \u001b[39mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2242\u001b[0m     values \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32mc:\\Users\\leo57\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2279\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2276\u001b[0m first \u001b[39m=\u001b[39m arrays[\u001b[39m0\u001b[39m]\n\u001b[0;32m   2277\u001b[0m shape \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(arrays),) \u001b[39m+\u001b[39m first\u001b[39m.\u001b[39mshape\n\u001b[1;32m-> 2279\u001b[0m stacked \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(shape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   2280\u001b[0m \u001b[39mfor\u001b[39;00m i, arr \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(arrays):\n\u001b[0;32m   2281\u001b[0m     stacked[i] \u001b[39m=\u001b[39m arr\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 180. MiB for an array with shape (5, 4729512) and data type int64"
     ]
    }
   ],
   "source": [
    "# Importation des 2 DataFrame\n",
    "df = pd.read_csv('./../../data/NBA Shot Locations 1997 - 2020.csv')\n",
    "rank = pd.read_csv('./../../data/ranking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43bf753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation_shot_location(df,annee):\n",
    "    # Récupération des 10 meilleurs joueurs\n",
    "    espn = pd.read_csv('./../../data/top_espn_actif.csv')\n",
    "    # On restreint la DataFrame aux 10 meilleurs joueurs\n",
    "    new_df = df.loc[df['Player Name'].isin(espn['player'])]\n",
    "    # On met la colonne Game Date en type datetime\n",
    "    new_df['Game Date']=pd.to_datetime(new_df['Game Date'],format = '%Y%m%d')\n",
    "    # On restreint à partir de l'année 2010\n",
    "    new_df= new_df.loc[new_df['Game Date'].dt.year >=annee]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06347310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation_ranking(ranking,annee):\n",
    "    # On modifie le type de la date pour correspondre avec l'autre DataFrame\n",
    "    ranking['STANDINGSDATE']=pd.to_datetime(ranking['STANDINGSDATE'],format = '%Y-%m-%d')\n",
    "    # On se restreint à au delà de 2010\n",
    "    ranking = ranking.loc[rank['STANDINGSDATE'].dt.year >= annee]\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43fece58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée une fonction qui prend en entrée un type d'action 'a' et retourne le taux de réussite associé.\n",
    "def find_val(df_tx_reussite,a):\n",
    "    return df_tx_reussite.loc[df_tx_reussite['Action Type'] == a]['Shot Made Flag'].values[0]\n",
    "\n",
    "# On crée une fonction qui à une valeur de taux de réussite donnée associe sa note\n",
    "def find_n(val,liste):\n",
    "    n = 0\n",
    "    for i in liste:\n",
    "        if val >= i:\n",
    "            n+=1\n",
    "    return n\n",
    "\n",
    "# Cette fonction crée la colonne difficulté. Pour cela, elle prend en entrée un entier n, elle parcourt toutes les lignes de \n",
    "# notre DataFrame. Pour chaque ligne elle récupère le taux de réussite de l'Action Type et lui associe sa note.\n",
    "def categ(df_tx_reussite,df,n):\n",
    "    quantile = list(df_tx_reussite['Shot Made Flag'].quantile(np.linspace(1/n,1,n)))\n",
    "    cat = []\n",
    "    for a in df['Action Type']:\n",
    "        val = find_n(find_val(df_tx_reussite,a),quantile)\n",
    "        cat.append(val)\n",
    "    return cat\n",
    "\n",
    "# Création de la variable shot_difficulty\n",
    "def shot_difficulty(df,n,data):\n",
    "    # On crée la DataFrame qui à chaque type de shoot associe le taux de réussite. (70 types de shoot)\n",
    "    df_tx_reussite = pd.DataFrame(data.groupby('Action Type')['Shot Made Flag'].mean().reset_index())\n",
    "    # On trouve les quantiles d'ordre n pour ces 70 valeurs.\n",
    "    quantile = list(df_tx_reussite['Shot Made Flag'].quantile(np.linspace(1/n,1,n)))\n",
    "    difficulty = categ(df_tx_reussite,df,n)\n",
    "    df['Shot Difficulty'] = difficulty\n",
    "    df = df.drop(['Action Type'],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed893750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction associe à chaque shot l'équipe adverse du shooter.\n",
    "def adversaire(df):\n",
    "    adv = []\n",
    "    new_df = df[['Team Name','Home Team','Away Team']]\n",
    "    for a in new_df.values:\n",
    "        if a[0] == a[1]:\n",
    "            adv.append(a[2])\n",
    "        else:\n",
    "            adv.append(a[1])\n",
    "    return adv\n",
    "\n",
    "def creation_pourcentage_adversaire(df,rank):\n",
    "    # On remplace le nom des équipes de la colonne Team Name par leur code en 3 lettres\n",
    "    new_df = df.replace(to_replace = ['New Orleans Hornets', 'Oklahoma City Thunder',\n",
    "       'Golden State Warriors', 'Cleveland Cavaliers', 'Miami Heat',\n",
    "       'Los Angeles Clippers', 'San Antonio Spurs', 'Houston Rockets',\n",
    "       'Portland Trail Blazers', 'New Orleans Pelicans',\n",
    "       'Milwaukee Bucks', 'LA Clippers', 'Toronto Raptors','New Orleans/Oklahoma City Hornets',\n",
    "       'Los Angeles Lakers','Seattle SuperSonics'],\n",
    "           value = ['NOP', 'OKC','GSW','CLE','MIA','LAC','SAS','HOU','POR','NOP','MIL','LAC','TOR','NOK','LAL','SEA'])\n",
    "    # On applique la fonction adversaire qui crée une colonne avec l'équipe adverse pour chaque shoot.\n",
    "    new_df['Adversaire'] = adversaire(new_df)\n",
    "    # On remplace les noms de la colonne TEAM de ranking pour que cela corresponde avec les valeurs de la colonne 'Adversaire'.\n",
    "    new_rank=rank.replace(to_replace = ['Denver', 'Memphis', 'New Orleans', 'Phoenix', 'LA Clippers',\n",
    "       'Sacramento', 'Utah', 'Portland', 'Dallas', 'Minnesota',\n",
    "       'Golden State', 'Oklahoma City', 'L.A. Lakers', 'San Antonio',\n",
    "       'Houston', 'Milwaukee', 'Boston', 'Cleveland', 'Brooklyn',\n",
    "       'Philadelphia', 'New York', 'Atlanta', 'Indiana', 'Miami',\n",
    "       'Toronto', 'Chicago', 'Orlando', 'Washington', 'Charlotte',\n",
    "       'Detroit', 'L.A. Clippers','New Jersey','Seattle', 'New Orleans/Oklahoma City',], \n",
    "                          value = ['DEN','MEM','NOP','PHX','LAC','SAC','UTA','POR',\n",
    "                                                          'DAL','MIN','GSW','OKC','LAL','SAS','HOU','MIL',\n",
    "                                                          'BOS','CLE','BKN','PHI','NYK','ATL','IND','MIA',\n",
    "                                                          'TOR','CHI','ORL','WAS','CHA','DET','LAC','NJN','SEA','NOK'])\n",
    "    # On joint les 2 dataframe sur la date et l'équipe adverse par une jointure gauche pour conserver tous les shoots.\n",
    "    final_df = new_df.merge(new_rank,how = 'left',right_on = ['STANDINGSDATE','TEAM'],left_on = ['Game Date','Adversaire'])\n",
    "    # On applique une correction à la colonne pourcentage de victoire pour gérer les valeurs extrêmes du début de saison\n",
    "    final_df['W_PCT_2'] = [a if a>0.2 else final_df['W_PCT'].mean() for a in final_df['W_PCT']]\n",
    "    # On enlève la colonne avec beaucoup de NaN et l'ancienne colonne 'W_PCT'\n",
    "    final_df = final_df.drop(['RETURNTOPLAY','W_PCT'],axis = 1)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e43450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(df,colonne):\n",
    "    # Cette fonction sert juste à rendre le get_dummies plus rapide\n",
    "    dummies = pd.get_dummies(df[colonne])\n",
    "    new_df = pd.concat([df,dummies],axis=1)\n",
    "    new_df=new_df.drop([colonne],axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6522ef23",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "def final_df(df,rank,n,annee):\n",
    "    # On prépare la DataFrame \"NBA Shot Locations 1997 - 2020\"\n",
    "    shot_loc = preparation_shot_location(df,annee)\n",
    "    # On prépare la DataFrame \"Ranking\"\n",
    "    ranking = preparation_ranking(rank,annee)\n",
    "    # On crée le pourcentage de l'équipe adverse\n",
    "    new_df = creation_pourcentage_adversaire(shot_loc,ranking)\n",
    "    # On crée les variables joueurs à l'aide d'un get_dummies\n",
    "    final_df = get_dummies(new_df,'Player Name')\n",
    "    # On crée la variable \"Last Minute\" à l'aide de la colonne \"Minutes Remaining\"\n",
    "    last_minute = [1 if a == 0 else 0 for a in final_df[\"Minutes Remaining\"]]\n",
    "    final_df['Last Minute'] = last_minute\n",
    "    # On choisit les colonnes qui nous intéresse\n",
    "    dff = final_df.loc[:,['Last Minute','Action Type','W_PCT_2','Shot Made Flag','Damian Lillard','LeBron James',\n",
    "                         'Kevin Durant','Chris Paul','Russell Westbrook','James Harden','Anthony Davis','Giannis Antetokounmpo',\n",
    "                         'Kawhi Leonard','Stephen Curry','Shot Distance']]\n",
    "    # On sépare en je de tes et jeu d'entraînement\n",
    "    target = dff['Shot Made Flag']\n",
    "    data_train,data_test,y_train,y_test = train_test_split(dff,target,random_state=10,test_size=0.2)\n",
    "    # On crée la variable \"Shot Difficulty\" calibrés sur les données de X_train et appliqués à X_test et X_train\n",
    "    X_train = shot_difficulty(data_train,n,data_train)\n",
    "    X_test = shot_difficulty(data_test,n,data_train)\n",
    "    X_train = X_train.drop([\"Shot Made Flag\"],axis=1)\n",
    "    X_test = X_test.drop([\"Shot Made Flag\"],axis=1)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2092b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_colonne(df,columns):\n",
    "    #Permet de choisir les colonnes que l'on souhaite.\n",
    "    return df.loc[:,columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4b7b17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leo57\\OneDrive\\Documents\\Projet Datascientest\\Fev23_BDS_NBA\\notebooks\\preprocessing\\Preprocessing final.ipynb Cell 10\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/leo57/OneDrive/Documents/Projet%20Datascientest/Fev23_BDS_NBA/notebooks/preprocessing/Preprocessing%20final.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m (X_train,X_test,y_train,y_test)\u001b[39m=\u001b[39mfinal_df(df,rank,\u001b[39m20\u001b[39m,\u001b[39m2010\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "(X_train,X_test,y_train,y_test)=final_df(df,rank,20,2010)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
